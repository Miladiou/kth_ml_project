{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RVM classification for a mixture of Gaussians - RÃ©mi Lacombe - January 2018\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Creates (or imports) dataset\n",
    "\n",
    "# Says which dataset is chosen: 0 for Ripley's Gaussians/ 1 for Pima indians/ 2 for USPS hand-written digits\n",
    "set_option = 1\n",
    "\n",
    "\n",
    "# Classification on Ripley's Gaussians dataset\n",
    "if (set_option == 0):\n",
    "\n",
    "    big_ripley = np.zeros((250,3))\n",
    "\n",
    "    # Converts the dataset from text file to Python arrays\n",
    "    my_file = open('synth.tr','r')\n",
    "\n",
    "    index = 0\n",
    "    number = ''\n",
    "\n",
    "    for line in my_file:\n",
    "        for i in range(len(line)):\n",
    "            if (line[i] == ' '):\n",
    "                if ((len(number) > 0) | (i == len(line)-1)):\n",
    "                    big_ripley[index/3][index%3] = float(number)\n",
    "                    index += 1\n",
    "                number = ''\n",
    "            else:\n",
    "                number += line[i]\n",
    "\n",
    "    my_file.close()\n",
    "\n",
    "    X_ripley = big_ripley[:,0]\n",
    "    Y_ripley = big_ripley[:,1]\n",
    "    t_ripley = big_ripley[:,2]\n",
    "    t_ripley[-1] = 1\n",
    "    \n",
    "    indices_0 = [n for n in range(125)]\n",
    "    indices_1 = [n for n in range(125,250)]\n",
    "\n",
    "    '''\n",
    "    plt.scatter(X_ripley[indices_0], Y_ripley[indices_0], c='r', linewidths = 0.1, marker = 'o')\n",
    "    plt.scatter(X_ripley[indices_1], Y_ripley[indices_1], c='b', linewidths = 0.1, marker = 'v')\n",
    "    plt.show()\n",
    "    '''\n",
    "    \n",
    "    # Let us choose 100 points at random in this dataset\n",
    "    \n",
    "    N = 100\n",
    "    \n",
    "    random_indices = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        random = np.random.randint(0,250)\n",
    "        while random in random_indices:\n",
    "            random = np.random.randint(0,250)\n",
    "        random_indices[i] = int(random)\n",
    "    \n",
    "    random_indices = random_indices.astype(int)\n",
    "    random_indices = np.sort(random_indices)\n",
    "    \n",
    "    data_points = np.array([X_ripley[random_indices], Y_ripley[random_indices]])\n",
    "    data_points = np.transpose(data_points)\n",
    "    \n",
    "    t = t_ripley[random_indices]\n",
    "    \n",
    "    break_index = 0\n",
    "    while random_indices[break_index] < 125:\n",
    "        break_index += 1\n",
    "\n",
    "    indices_0_r = [random_indices[n] for n in range(break_index)]\n",
    "    indices_1_r = [random_indices[n] for n in range(break_index,N)]\n",
    "    \n",
    "    plt.scatter(X_ripley[indices_0_r], Y_ripley[indices_0_r], c='r', linewidths = 0.1, marker = 'o')\n",
    "    plt.scatter(X_ripley[indices_1_r], Y_ripley[indices_1_r], c='b', linewidths = 0.1, marker = 'v')\n",
    "    plt.title(\"Ripley's Gaussians dataset with 100 data points chosen at random\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# Classification on Pima diabetes dataset\n",
    "if (set_option == 1):\n",
    "    \n",
    "    N = 200\n",
    "\n",
    "    data_points = np.zeros((200,7))\n",
    "    t = np.zeros(200)\n",
    "\n",
    "    # Converts the dataset from text file to Python arrays\n",
    "    my_file = open('pima.tr','r')\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    for line in my_file:\n",
    "        number = ''\n",
    "        for i in range(len(line)):\n",
    "            if (line[i] == ' '):\n",
    "                if (len(number) > 0):\n",
    "                    data_points[index/7][index%7] = float(number)\n",
    "                    index += 1\n",
    "                number = ''\n",
    "            elif (i == len(line) - 2):\n",
    "                t[index/7 - 1] = float(line[i])\n",
    "            else:\n",
    "                number += line[i]\n",
    "\n",
    "    my_file.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "# Classification on USPS hand-written digits\n",
    "if (set_option == 2):\n",
    "    \n",
    "    N = 7291\n",
    "\n",
    "    data_points = np.zeros((7291,256))\n",
    "    t = np.zeros(7291)\n",
    "\n",
    "    # Converts the dataset from text file to Python arrays\n",
    "    my_file = open('usps.tr','r')\n",
    "\n",
    "    index = 0\n",
    "    \n",
    "    it_is_a_10 = 0\n",
    "\n",
    "    for line in my_file:\n",
    "        \n",
    "        number = ''\n",
    "        \n",
    "        for i in range(len(line)):\n",
    "            \n",
    "            if (it_is_a_10 == 1):\n",
    "                it_is_a_10 = 0\n",
    "                \n",
    "            elif (i == 0):\n",
    "                if (line[i+1] == '0'):\n",
    "                    t[index/256] = 10\n",
    "                    it_is_a_10 = 1\n",
    "                else:\n",
    "                    t[index/256] = int(line[i])\n",
    "                \n",
    "            elif (line[i] == ':'):\n",
    "                number = ''\n",
    "                \n",
    "            elif (line[i] == ' '):\n",
    "                if (len(number) > 0):\n",
    "                    if (index/256 == 7291):\n",
    "                        print(line)\n",
    "                    data_points[index/256][index%256] = float(number)\n",
    "                    index += 1\n",
    "                number = ''\n",
    "                \n",
    "            elif (i == len(line) - 2):\n",
    "                number = ''\n",
    "                j = i\n",
    "                while (line[j] != ':'):\n",
    "                    number += line[j]\n",
    "                    j -= 1\n",
    "                new_number = ''\n",
    "                for k in range(len(number)):\n",
    "                    new_number += number[len(number) - 1 - k]\n",
    "                data_points[index/256][index%256] = float(new_number)\n",
    "                index += 1\n",
    "                \n",
    "            else:\n",
    "                number += line[i]\n",
    "                \n",
    "    my_file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates Kernel function\n",
    "\n",
    "kernel_option = 49\n",
    "\n",
    "def Gaussian_kernel(x,y):\n",
    "    return np.exp(-sum((x-y)*(x-y))/pow(kernel_option,2))\n",
    "\n",
    "def y(x_index, w, Phi):\n",
    "    return sum(Phi[x_index]*w)\n",
    "\n",
    "def logistic_sigmoid(y):\n",
    "    return 1/(1 + np.exp(-y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 44 130 147 158 187]\n",
      "[ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -1.30207333  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          2.74993566  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      " -6.268906    0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -2.36438115  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          3.02067842\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Performs the classification\n",
    "\n",
    "w = 0.01*np.ones(N+1)\n",
    "w_new = w\n",
    "\n",
    "# The hyperparameters alpha_i are initially taken to be 1\n",
    "alpha = np.ones(N+1)\n",
    "A = np.diag(alpha)\n",
    "\n",
    "# Keeps track of the indices of the relevance vectors\n",
    "alpha_indices = np.linspace(0,N,N+1)\n",
    "alpha_indices = alpha_indices.astype(int)\n",
    "\n",
    "# Creates the design matrix Phi\n",
    "Phi = np.ones((N,N+1))\n",
    "\n",
    "for i in range(N):\n",
    "    \n",
    "    for j in range(i+1):\n",
    "        \n",
    "        Phi[i][j+1] = Gaussian_kernel(data_points[i], data_points[j])\n",
    "        Phi[j][i+1] = Phi[i][j+1]\n",
    "        \n",
    "new_Phi = Phi\n",
    "\n",
    "# Deals with the special case where w_0 is not relevant\n",
    "not_removed_0 = 1\n",
    "        \n",
    "        \n",
    "# Main loop for the re-estimation of alpha\n",
    "for i in range(500):\n",
    "        \n",
    "        \n",
    "    k = len(alpha_indices)\n",
    "    \n",
    "    # Checks for infinite loops in the optimization algorithm\n",
    "    iteration_number = 0\n",
    "\n",
    "    update_quantity = np.ones(N+1)\n",
    "    \n",
    "    # Newton's optimization algorithm is used to find wmp\n",
    "    while not all(abs(j) < 1e-14 for j in update_quantity):\n",
    "            \n",
    "        logistic_array = np.array([logistic_sigmoid(y(n, w, Phi)) for n in range(N)])\n",
    "        B = np.diag(logistic_array*(1-logistic_array))\n",
    "\n",
    "        gradient = np.dot(np.transpose(new_Phi), t - logistic_array) - np.dot(A, w_new)\n",
    "        \n",
    "        hessian = -np.dot(np.transpose(new_Phi), np.dot(B, new_Phi)) - A\n",
    "\n",
    "        update_quantity = np.dot(np.linalg.inv(hessian), gradient)\n",
    "    \n",
    "        w_new = w_new - update_quantity\n",
    "        \n",
    "        w[alpha_indices] = w_new\n",
    "        \n",
    "        iteration_number += 1\n",
    "    \n",
    "        if (iteration_number == 100):\n",
    "            print(\"OBS ! Infinite loop.\")\n",
    "            break\n",
    "    \n",
    "            \n",
    "    # Updates B with the new value of wmp \n",
    "    logistic_array = np.array([logistic_sigmoid(y(n, w, Phi)) for n in range(N)])\n",
    "    B = np.diag(logistic_array*(1-logistic_array))\n",
    "    \n",
    "    small_Sigma = np.linalg.inv(np.dot(np.transpose(new_Phi), np.dot(B, new_Phi)) + A)\n",
    "    \n",
    "    #w_new_test = np.dot(np.linalg.inv(A), np.dot(np.transpose(new_Phi), t - logistic_array))\n",
    "    \n",
    "    C = np.zeros((k, N+1))\n",
    "    C[:, alpha_indices] = small_Sigma\n",
    "    \n",
    "    Sigma = np.zeros((N+1,N+1))\n",
    "    Sigma[alpha_indices,:] = C\n",
    "    \n",
    "    mu = w_new\n",
    "    \n",
    "    gamma = 1 - alpha*np.diag(small_Sigma)\n",
    "    alpha = gamma/pow(mu, 2)\n",
    "    \n",
    "    # Prunes basis functions for which alpha_i tends to infinity\n",
    "    prune = np.where(alpha > 1e12)[0]\n",
    "    \n",
    "    # Keeps track of the indices that are removed\n",
    "    alpha_indices = np.delete(alpha_indices, prune)\n",
    "    \n",
    "    if ((0 in prune) & (not_removed_0)):\n",
    "        \n",
    "        prune = np.delete(prune, 0)\n",
    "        prune = prune - 1\n",
    "        not_removed_0 = 0\n",
    "        \n",
    "        alpha = np.delete(alpha, 0)\n",
    "        w_new = np.delete(w_new, 0)\n",
    "        new_Phi = np.delete(new_Phi, 0, 1)\n",
    "        \n",
    "    if (len(prune) > 0):\n",
    "        \n",
    "        alpha = np.delete(alpha, prune)\n",
    "        w_new = np.delete(w_new, prune)\n",
    "\n",
    "        # Checks if hyperparameter of index 0 has been removed\n",
    "        if (not_removed_0):\n",
    "            new_Phi = np.delete(new_Phi, prune, 1)\n",
    "        else:\n",
    "            new_Phi = np.delete(new_Phi, prune, 1)\n",
    "    \n",
    "    A = np.diag(alpha)\n",
    "    \n",
    "    # Updates parameters w (this can also be commented to get another slightly different w)\n",
    "    w = np.zeros(N+1)\n",
    "    w[alpha_indices] = w_new\n",
    "\n",
    "    \n",
    "# Increase the number of iterations in the main loop if some values of w seem too small\n",
    "print(alpha_indices)\n",
    "print(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (7,) (2,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-7c4f6aefbdd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mposterior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_ripley_test\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mY_ripley_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Computes the coordinates of the relevance vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-7c4f6aefbdd0>\u001b[0m in \u001b[0;36mposterior\u001b[0;34m(new_point)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mGaussian_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_points\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogistic_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-344f355617d8>\u001b[0m in \u001b[0;36mGaussian_kernel\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mGaussian_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_option\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPhi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (7,) (2,) "
     ]
    }
   ],
   "source": [
    "# Makes predictions and plots decision boundary\n",
    "\n",
    "# Defines the precision of the boundary\n",
    "set_size = 50\n",
    "\n",
    "X_ripley_test = np.linspace(-1.3, 1, set_size)\n",
    "Y_ripley_test = np.linspace(-0.3, 1.2, set_size)\n",
    "\n",
    "\n",
    "# Computes the posterior value for every new point (OBS: the case where the bias remains is not included)\n",
    "def posterior(new_point):\n",
    "    \n",
    "    result = 0\n",
    "    \n",
    "    for i in range(len(alpha_indices)):\n",
    "        \n",
    "        index = alpha_indices[i]\n",
    "        result += w[index]*Gaussian_kernel(data_points[index-1], new_point)\n",
    "        \n",
    "    return(logistic_sigmoid(result))\n",
    "\n",
    "\n",
    "values = np.array([[posterior((x, y)) for x in X_ripley_test] for y in Y_ripley_test])\n",
    "\n",
    "# Computes the coordinates of the relevance vectors\n",
    "a = data_points[alpha_indices-1]\n",
    "X_relevance = a[:,0]\n",
    "Y_relevance = a[:,1]\n",
    "\n",
    "# Plots the decision boundary\n",
    "plt.contour(X_ripley_test, Y_ripley_test, values, 0.5, colors = 'black', linewidths = 1, linestyles='dashed')\n",
    "        \n",
    "plt.scatter(X_ripley[indices_0_r], Y_ripley[indices_0_r], c='r', linewidths = 0.1, marker = 'o')\n",
    "plt.scatter(X_ripley[indices_1_r], Y_ripley[indices_1_r], c='b', linewidths = 0.1, marker = 'v')\n",
    "plt.scatter(X_relevance, Y_relevance, s=100, facecolors='none', edgecolors='b')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of errors is 67.\n",
      "The number of errors is 20.1807228916%.\n"
     ]
    }
   ],
   "source": [
    "# Verifies the result with the provided test sets \n",
    "\n",
    "if (set_option == 0):\n",
    "\n",
    "    test_ripley = np.zeros((1000,3))\n",
    "\n",
    "    # Converts the dataset from text file to Python arrays\n",
    "    my_file = open('synth.te','r')\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    for line in my_file:\n",
    "        number = ''\n",
    "        for i in range(len(line)):\n",
    "            if (i == len(line)-2):\n",
    "                test_ripley[index/3][index%3] = float(line[i])\n",
    "                index += 1\n",
    "            elif (line[i] == ' '):\n",
    "                if (len(number) > 0):\n",
    "                    test_ripley[index/3][index%3] = float(number)\n",
    "                    index += 1\n",
    "                number = ''\n",
    "            else:\n",
    "                number += line[i]\n",
    "\n",
    "    my_file.close()\n",
    "\n",
    "    \n",
    "    # Counts the proportion of errors on the test set\n",
    "    error_count = 0\n",
    "    \n",
    "    for i in range(1000):\n",
    "        \n",
    "        result = 0\n",
    "        new_point = test_ripley[i,0:2]\n",
    "\n",
    "        for j in range(len(alpha_indices)):\n",
    "\n",
    "            index = alpha_indices[j]\n",
    "            result += w[index]*Gaussian_kernel(data_points[index-1], new_point)\n",
    "        \n",
    "        if not (abs(logistic_sigmoid(result) - test_ripley[i,2]) < 0.5):\n",
    "            \n",
    "            error_count += 1\n",
    "\n",
    "    print(\"The test error is \" + str(error_count/10.) + \"%.\")\n",
    "    \n",
    "    \n",
    "\n",
    "if (set_option == 1):\n",
    "\n",
    "    data_test_pima = np.zeros((332,7))\n",
    "    t_test_pima = np.zeros(332)\n",
    "\n",
    "    # Converts the dataset from text file to Python arrays\n",
    "    my_file = open('pima.te','r')\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    for line in my_file:\n",
    "        number = ''\n",
    "        for i in range(len(line)):\n",
    "            if (line[i] == ' '):\n",
    "                if (len(number) > 0):\n",
    "                    data_test_pima[index/7][index%7] = float(number)\n",
    "                    index += 1\n",
    "                number = ''\n",
    "            elif (i == len(line) - 2):\n",
    "                t_test_pima[index/7 - 1] = float(line[i])\n",
    "            else:\n",
    "                number += line[i]\n",
    "                \n",
    "    my_file.close()\n",
    "    \n",
    "    \n",
    "    # Counts the number of errors on the test set\n",
    "    error_count = 0\n",
    "    \n",
    "    for i in range(332):\n",
    "        \n",
    "        result = 0\n",
    "        new_point = data_test_pima[i]\n",
    "\n",
    "        for j in range(len(alpha_indices)):\n",
    "\n",
    "            index = alpha_indices[j]\n",
    "            result += w[index]*Gaussian_kernel(data_points[index-1], new_point)\n",
    "        \n",
    "        if not (abs(logistic_sigmoid(result) - t_test_pima[i]) < 0.5):\n",
    "            \n",
    "            error_count += 1\n",
    "\n",
    "    print(\"The number of errors is \" + str(error_count) + \".\")\n",
    "    print(\"The number of errors is \" + str(error_count/3.32) + \"%.\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
