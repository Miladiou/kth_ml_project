\section{Method}
%TODO:
RVMs can be thought of as SVMs that use a Bayesian treatment. Instead of providing direct answers, RVMs return probabilistic predictions. We start of by computing the hyperparameters $\alpha,\sigma^2$ of the priors for each weight (all of the priors being independent) based on the data. Expectation-maximization (EM) method is used to  find optimal values of $\alpha,\sigma^2$ (i.e. those values that maximize the \textit{evidence}). This is what constitutes the learning process. %Inference is then computed by 

%in SVM, support vectors are close to the decision boundary whereas the relevance vectors describe prototypicla examples of classes.